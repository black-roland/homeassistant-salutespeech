# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: custom_components/salutespeech/api/grpc/recognition.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import enum_type_wrapper
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.protobuf import duration_pb2 as google_dot_protobuf_dot_duration__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n9custom_components/salutespeech/api/grpc/recognition.proto\x12\x1asmartspeech.recognition.v2\x1a\x1egoogle/protobuf/duration.proto\"y\n\x12RecognitionRequest\x12\x41\n\x07options\x18\x01 \x01(\x0b\x32..smartspeech.recognition.v2.RecognitionOptionsH\x00\x12\x15\n\x0b\x61udio_chunk\x18\x02 \x01(\x0cH\x00\x42\t\n\x07request\"\x9a\x02\n\x13RecognitionResponse\x12\x42\n\rtranscription\x18\x01 \x01(\x0b\x32).smartspeech.recognition.v2.TranscriptionH\x00\x12?\n\x0c\x62\x61\x63kend_info\x18\x02 \x01(\x0b\x32\'.smartspeech.recognition.v2.BackendInfoH\x00\x12<\n\x07insight\x18\x03 \x01(\x0b\x32).smartspeech.recognition.v2.InsightResultH\x00\x12\x34\n\x03vad\x18\x04 \x01(\x0b\x32%.smartspeech.recognition.v2.VADResultH\x00\x42\n\n\x08response\"\x91\x03\n\rTranscription\x12\x0f\n\x07\x63hannel\x18\x01 \x01(\x05\x12\x37\n\x07results\x18\x02 \x03(\x0b\x32&.smartspeech.recognition.v2.Hypothesis\x12\x0b\n\x03\x65ou\x18\x03 \x01(\x08\x12\x39\n\neou_reason\x18\x04 \x01(\x0e\x32%.smartspeech.recognition.v2.EouReason\x12\x38\n\x15processed_audio_start\x18\x05 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x36\n\x13processed_audio_end\x18\x06 \x01(\x0b\x32\x19.google.protobuf.Duration\x12=\n\x0f\x65motions_result\x18\x07 \x01(\x0b\x32$.smartspeech.recognition.v2.Emotions\x12=\n\x0cspeaker_info\x18\x08 \x01(\x0b\x32\'.smartspeech.recognition.v2.SpeakerInfo\"\'\n\rInsightResult\x12\x16\n\x0einsight_result\x18\n \x01(\t\"\x92\x01\n\tVADResult\x12\x0f\n\x07\x63hannel\x18\x01 \x01(\x05\x12\x37\n\x14processed_audio_time\x18\x02 \x01(\x0b\x32\x19.google.protobuf.Duration\x12;\n\x18utterance_detection_time\x18\x03 \x01(\x0b\x32\x19.google.protobuf.Duration\"\x1e\n\x0cOptionalBool\x12\x0e\n\x06\x65nable\x18\x01 \x01(\x08\"\x96\x08\n\x12RecognitionOptions\x12T\n\x0e\x61udio_encoding\x18\x01 \x01(\x0e\x32<.smartspeech.recognition.v2.RecognitionOptions.AudioEncoding\x12\x13\n\x0bsample_rate\x18\x02 \x01(\x05\x12\x16\n\x0e\x63hannels_count\x18\x03 \x01(\x05\x12\x10\n\x08language\x18\x04 \x01(\t\x12\r\n\x05model\x18\x05 \x01(\t\x12H\n\x16\x65nable_multi_utterance\x18\x06 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12H\n\x16\x65nable_partial_results\x18\x07 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12\x18\n\x10hypotheses_count\x18\x08 \x01(\x05\x12\x34\n\x11no_speech_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x35\n\x12max_speech_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x30\n\x05hints\x18\x0b \x01(\x0b\x32!.smartspeech.recognition.v2.Hints\x12X\n\x1aspeaker_separation_options\x18\x0c \x01(\x0b\x32\x34.smartspeech.recognition.v2.SpeakerSeparationOptions\x12O\n\x15normalization_options\x18\r \x01(\x0b\x32\x30.smartspeech.recognition.v2.NormalizationOptions\x12\x16\n\x0einsight_models\x18\x0e \x03(\t\x12<\n\nenable_vad\x18\x0f \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12H\n\x16\x63ustom_ws_flow_control\x18\x10 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12H\n\x16\x65nable_long_utterances\x18\x11 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\"z\n\rAudioEncoding\x12\x1e\n\x1a\x41UDIO_ENCODING_UNSPECIFIED\x10\x00\x12\r\n\tPCM_S16LE\x10\x01\x12\x08\n\x04OPUS\x10\x02\x12\x07\n\x03MP3\x10\x03\x12\x08\n\x04\x46LAC\x10\x04\x12\x08\n\x04\x41LAW\x10\x05\x12\t\n\x05MULAW\x10\x06\x12\x08\n\x04G729\x10\x07\"\x93\x03\n\x14NormalizationOptions\x12\x38\n\x06\x65nable\x18\x01 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12\x42\n\x10profanity_filter\x18\x02 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12=\n\x0bpunctuation\x18\x03 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12@\n\x0e\x63\x61pitalization\x18\x04 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12:\n\x08question\x18\x05 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12@\n\x0e\x66orce_cyrillic\x18\x06 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\"^\n\x05Hints\x12\r\n\x05words\x18\x01 \x03(\t\x12\x16\n\x0e\x65nable_letters\x18\x02 \x01(\x08\x12.\n\x0b\x65ou_timeout\x18\x03 \x01(\x0b\x32\x19.google.protobuf.Duration\"[\n\x18SpeakerSeparationOptions\x12\x0e\n\x06\x65nable\x18\x01 \x01(\x08\x12 \n\x18\x65nable_only_main_speaker\x18\x02 \x01(\x08\x12\r\n\x05\x63ount\x18\x03 \x01(\x05\"\xc5\x02\n\nHypothesis\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x17\n\x0fnormalized_text\x18\x02 \x01(\t\x12(\n\x05start\x18\x03 \x01(\x0b\x32\x19.google.protobuf.Duration\x12&\n\x03\x65nd\x18\x04 \x01(\x0b\x32\x19.google.protobuf.Duration\x12M\n\x0fword_alignments\x18\x05 \x03(\x0b\x32\x34.smartspeech.recognition.v2.Hypothesis.WordAlignment\x1ao\n\rWordAlignment\x12\x0c\n\x04word\x18\x01 \x01(\t\x12(\n\x05start\x18\x02 \x01(\x0b\x32\x19.google.protobuf.Duration\x12&\n\x03\x65nd\x18\x03 \x01(\x0b\x32\x19.google.protobuf.Duration\"\xb5\x01\n\x08\x45motions\x12\x10\n\x08positive\x18\x01 \x01(\x02\x12\x0f\n\x07neutral\x18\x02 \x01(\x02\x12\x10\n\x08negative\x18\x03 \x01(\x02\x12\x12\n\npositive_a\x18\x04 \x01(\x02\x12\x11\n\tneutral_a\x18\x05 \x01(\x02\x12\x12\n\nnegative_a\x18\x06 \x01(\x02\x12\x12\n\npositive_t\x18\x07 \x01(\x02\x12\x11\n\tneutral_t\x18\x08 \x01(\x02\x12\x12\n\nnegative_t\x18\t \x01(\x02\"P\n\x0b\x42\x61\x63kendInfo\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x15\n\rmodel_version\x18\x02 \x01(\t\x12\x16\n\x0eserver_version\x18\x03 \x01(\t\"B\n\x0bSpeakerInfo\x12\x12\n\nspeaker_id\x18\x01 \x01(\x05\x12\x1f\n\x17main_speaker_confidence\x18\x02 \x01(\x02*X\n\tEouReason\x12\x0f\n\x0bUNSPECIFIED\x10\x00\x12\x0b\n\x07ORGANIC\x10\x01\x12\x15\n\x11NO_SPEECH_TIMEOUT\x10\x02\x12\x16\n\x12MAX_SPEECH_TIMEOUT\x10\x03\x32\x7f\n\x0bSmartSpeech\x12p\n\tRecognize\x12..smartspeech.recognition.v2.RecognitionRequest\x1a/.smartspeech.recognition.v2.RecognitionResponse(\x01\x30\x01\x42\x13\n\x04TODOZ\x0b./;protocolb\x06proto3')

_EOUREASON = DESCRIPTOR.enum_types_by_name['EouReason']
EouReason = enum_type_wrapper.EnumTypeWrapper(_EOUREASON)
UNSPECIFIED = 0
ORGANIC = 1
NO_SPEECH_TIMEOUT = 2
MAX_SPEECH_TIMEOUT = 3


_RECOGNITIONREQUEST = DESCRIPTOR.message_types_by_name['RecognitionRequest']
_RECOGNITIONRESPONSE = DESCRIPTOR.message_types_by_name['RecognitionResponse']
_TRANSCRIPTION = DESCRIPTOR.message_types_by_name['Transcription']
_INSIGHTRESULT = DESCRIPTOR.message_types_by_name['InsightResult']
_VADRESULT = DESCRIPTOR.message_types_by_name['VADResult']
_OPTIONALBOOL = DESCRIPTOR.message_types_by_name['OptionalBool']
_RECOGNITIONOPTIONS = DESCRIPTOR.message_types_by_name['RecognitionOptions']
_NORMALIZATIONOPTIONS = DESCRIPTOR.message_types_by_name['NormalizationOptions']
_HINTS = DESCRIPTOR.message_types_by_name['Hints']
_SPEAKERSEPARATIONOPTIONS = DESCRIPTOR.message_types_by_name['SpeakerSeparationOptions']
_HYPOTHESIS = DESCRIPTOR.message_types_by_name['Hypothesis']
_HYPOTHESIS_WORDALIGNMENT = _HYPOTHESIS.nested_types_by_name['WordAlignment']
_EMOTIONS = DESCRIPTOR.message_types_by_name['Emotions']
_BACKENDINFO = DESCRIPTOR.message_types_by_name['BackendInfo']
_SPEAKERINFO = DESCRIPTOR.message_types_by_name['SpeakerInfo']
_RECOGNITIONOPTIONS_AUDIOENCODING = _RECOGNITIONOPTIONS.enum_types_by_name['AudioEncoding']
RecognitionRequest = _reflection.GeneratedProtocolMessageType('RecognitionRequest', (_message.Message,), {
  'DESCRIPTOR' : _RECOGNITIONREQUEST,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.RecognitionRequest)
  })
_sym_db.RegisterMessage(RecognitionRequest)

RecognitionResponse = _reflection.GeneratedProtocolMessageType('RecognitionResponse', (_message.Message,), {
  'DESCRIPTOR' : _RECOGNITIONRESPONSE,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.RecognitionResponse)
  })
_sym_db.RegisterMessage(RecognitionResponse)

Transcription = _reflection.GeneratedProtocolMessageType('Transcription', (_message.Message,), {
  'DESCRIPTOR' : _TRANSCRIPTION,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.Transcription)
  })
_sym_db.RegisterMessage(Transcription)

InsightResult = _reflection.GeneratedProtocolMessageType('InsightResult', (_message.Message,), {
  'DESCRIPTOR' : _INSIGHTRESULT,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.InsightResult)
  })
_sym_db.RegisterMessage(InsightResult)

VADResult = _reflection.GeneratedProtocolMessageType('VADResult', (_message.Message,), {
  'DESCRIPTOR' : _VADRESULT,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.VADResult)
  })
_sym_db.RegisterMessage(VADResult)

OptionalBool = _reflection.GeneratedProtocolMessageType('OptionalBool', (_message.Message,), {
  'DESCRIPTOR' : _OPTIONALBOOL,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.OptionalBool)
  })
_sym_db.RegisterMessage(OptionalBool)

RecognitionOptions = _reflection.GeneratedProtocolMessageType('RecognitionOptions', (_message.Message,), {
  'DESCRIPTOR' : _RECOGNITIONOPTIONS,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.RecognitionOptions)
  })
_sym_db.RegisterMessage(RecognitionOptions)

NormalizationOptions = _reflection.GeneratedProtocolMessageType('NormalizationOptions', (_message.Message,), {
  'DESCRIPTOR' : _NORMALIZATIONOPTIONS,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.NormalizationOptions)
  })
_sym_db.RegisterMessage(NormalizationOptions)

Hints = _reflection.GeneratedProtocolMessageType('Hints', (_message.Message,), {
  'DESCRIPTOR' : _HINTS,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.Hints)
  })
_sym_db.RegisterMessage(Hints)

SpeakerSeparationOptions = _reflection.GeneratedProtocolMessageType('SpeakerSeparationOptions', (_message.Message,), {
  'DESCRIPTOR' : _SPEAKERSEPARATIONOPTIONS,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.SpeakerSeparationOptions)
  })
_sym_db.RegisterMessage(SpeakerSeparationOptions)

Hypothesis = _reflection.GeneratedProtocolMessageType('Hypothesis', (_message.Message,), {

  'WordAlignment' : _reflection.GeneratedProtocolMessageType('WordAlignment', (_message.Message,), {
    'DESCRIPTOR' : _HYPOTHESIS_WORDALIGNMENT,
    '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
    # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.Hypothesis.WordAlignment)
    })
  ,
  'DESCRIPTOR' : _HYPOTHESIS,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.Hypothesis)
  })
_sym_db.RegisterMessage(Hypothesis)
_sym_db.RegisterMessage(Hypothesis.WordAlignment)

Emotions = _reflection.GeneratedProtocolMessageType('Emotions', (_message.Message,), {
  'DESCRIPTOR' : _EMOTIONS,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.Emotions)
  })
_sym_db.RegisterMessage(Emotions)

BackendInfo = _reflection.GeneratedProtocolMessageType('BackendInfo', (_message.Message,), {
  'DESCRIPTOR' : _BACKENDINFO,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.BackendInfo)
  })
_sym_db.RegisterMessage(BackendInfo)

SpeakerInfo = _reflection.GeneratedProtocolMessageType('SpeakerInfo', (_message.Message,), {
  'DESCRIPTOR' : _SPEAKERINFO,
  '__module__' : 'custom_components.salutespeech.api.grpc.recognition_pb2'
  # @@protoc_insertion_point(class_scope:smartspeech.recognition.v2.SpeakerInfo)
  })
_sym_db.RegisterMessage(SpeakerInfo)

_SMARTSPEECH = DESCRIPTOR.services_by_name['SmartSpeech']
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'\n\004TODOZ\013./;protocol'
  _EOUREASON._serialized_start=3461
  _EOUREASON._serialized_end=3549
  _RECOGNITIONREQUEST._serialized_start=121
  _RECOGNITIONREQUEST._serialized_end=242
  _RECOGNITIONRESPONSE._serialized_start=245
  _RECOGNITIONRESPONSE._serialized_end=527
  _TRANSCRIPTION._serialized_start=530
  _TRANSCRIPTION._serialized_end=931
  _INSIGHTRESULT._serialized_start=933
  _INSIGHTRESULT._serialized_end=972
  _VADRESULT._serialized_start=975
  _VADRESULT._serialized_end=1121
  _OPTIONALBOOL._serialized_start=1123
  _OPTIONALBOOL._serialized_end=1153
  _RECOGNITIONOPTIONS._serialized_start=1156
  _RECOGNITIONOPTIONS._serialized_end=2202
  _RECOGNITIONOPTIONS_AUDIOENCODING._serialized_start=2080
  _RECOGNITIONOPTIONS_AUDIOENCODING._serialized_end=2202
  _NORMALIZATIONOPTIONS._serialized_start=2205
  _NORMALIZATIONOPTIONS._serialized_end=2608
  _HINTS._serialized_start=2610
  _HINTS._serialized_end=2704
  _SPEAKERSEPARATIONOPTIONS._serialized_start=2706
  _SPEAKERSEPARATIONOPTIONS._serialized_end=2797
  _HYPOTHESIS._serialized_start=2800
  _HYPOTHESIS._serialized_end=3125
  _HYPOTHESIS_WORDALIGNMENT._serialized_start=3014
  _HYPOTHESIS_WORDALIGNMENT._serialized_end=3125
  _EMOTIONS._serialized_start=3128
  _EMOTIONS._serialized_end=3309
  _BACKENDINFO._serialized_start=3311
  _BACKENDINFO._serialized_end=3391
  _SPEAKERINFO._serialized_start=3393
  _SPEAKERINFO._serialized_end=3459
  _SMARTSPEECH._serialized_start=3551
  _SMARTSPEECH._serialized_end=3678
# @@protoc_insertion_point(module_scope)
